# EE6222 Machine Vison

## 1.Content

1.Reference answers to final examination questions

2.PPT Example reference answer

## 2.Find out a mistake

As there is no standard answer, if you detect any error in the answer, it is due to my limited knowledge level. 

Please leave a message or send an email or some Wechat messages to me and I will update the version as soon as possible. 

My Email: freshmanfreshman0011@gmail.com

My Wechat: freshman2233

## 3.Declare

This resource is for learning and communication only. It is strictly prohibited for commercial use. Please delete it within 24 hours.

## 4.GitHub Sponsors

If you like this project, please consider supporting us through GitHub Sponsors! Thank you for your support!

## 5. Machine vision, exam scope

Chapter 2, linear translation invariant systems and transformations

In Chapter 9, dimension reduction of visual data is used as feature extraction

Chapter 10, Neural Networks and Deep Learning, from MLP to CNN

Chapter 12, Video analysis

Chapter 13, Video recognition

Chapter 14, 3D machine perception

Chapter 15, 3D machine Vision



## 6. Details

2 LSI linear translation invariant systems and transformations

2.1 Image decomposition and linear translation invariant image processing system

2.1.1. Image decomposition

2.1.2. Pulse

2.1.3. Translation and zooming pulse

2.1.4. Image decomposition





2.2 Two-dimensional convolution and its properties

2.2.1. Processing system

2.2.2. Linear processing system

2.2.3 Two-dimensional convolution

2.2.4 Convolution characteristics

2.2.5 Impulse response





2.3 Two-dimensional Fourier transform and its properties

2.3.1 Fourier transform and its inverse transformation

2.3.2 Independent and separable

2.3.3 Discrete Fourier Transform (DFT)

2.3.4 Discrete Fourier Transform (DFT) properties

2.3.4.1 Can be decomposed

2.3.4.2 Periodic, symmetric, linear, Convolution

2.3.4.3 Translation, rotation and translation do not change



2.4 Image Sampling

2.4.1 The image becomes discrete after continuous sampling

2.4.2 Sampling function

2.4.3 Image x sampling

2.4.4 Restoring Continuous Images

2.4.5 Sampling theorem



9 Visual data dimensionality reduction as feature extraction

9.1 Feature Extraction and Dimension Reduction

9.2 PCA, Principal component analysis

9.3 LDA, linear discriminant analysis

9.4 Classification of subspace/feature space



10 Neural Networks and Deep Learning, from MLP to CNN

10.1 Network structure and neuron model

10.1.1 Neural networks and deep CNNS

10.1.2 Neuron model

10.1.3 Activating functions



10.2 Multi-layer perceptron and backpropagation

10.2.1 ANN

10.2.1.1 Multi-Layer Perceptron (MLP)

10.2.1.2 Single-layer neural network

10.2.1.3 Learning curve and decision boundaries

10.2.1.4 Backpropagation

10.2.1.5 Local Minimum Problem

10.2.1.6 Understanding Overfitting

10.2.1.7 Conclusion of neural network



10.2.2 History of neural networks

10.2.3 Function of image recognition module

10.2.4 Supervised learning

10.2.5 Deep Learning

10.2.6 Problems with machine learning

10.2.7 Regularization



10.3 Convolutional Neural network CNN

10.3.1 Convolutional network CNN seems to be different from MLP

10.3.2 Features of Convolutional network CNN

10.3.3 1x1 Convolution

10.3.4 Advantages of Convolutional Networks, CNN







12 Video: Generated

12.1. Autoencoder



12.2. Antagonistic learning

12.2.1. GANs

12.2.2.Conditional GANs

12.2.3.Super Resolution GANs

12.2.4. CycleGAN

12.2.5.Diffusion Probabilistic Models

12.2.6.Video GAN

12.2.7.StoryGAN: A sequential condition GAN for story visualization

12.2.8. Two-stream VAN for video generation

12.2.9.Sora: Video generation model as a world simulator



13 Video: Analysis/Enhancement

13.1. Target detection and tracking

13.1.1 Detection and tracking

13.1.1.1 Detecting/dividing objects

13.1.1.2 Association Detection



13.1.2 Identifying the Re-ID again



13.1.3 Joint Detection and Embedding (JDE)







13.2. Behavior recognition

13.3. Video event/exception detection

13.3.1 Behavior Identification

13.3.2 Long-term Recurrent Convolutional Network Long-term Recurrent Convolutional Network

13.3.3 C3D: 3D convolutional network

13.3.4 Hidden Two streams



13.4. Video enhancement

13.4.1 Blur model

13.4.2 Deconvolution of fuzzy images

13.4.2.1 Point Spread Function (PSF) Point Spread Function (PSF)

13.4.3 Deep video deblur

13.4.4 Video Turbulence Effect Remove. Video turbulence effect remove



13.5. Optical flow

13.5.1 What is Optical Flow?

13.5.2 Optical Flow Hypothesis

13.5.2.1 Spatial coherence

13.5.2.2 Persistence of time

13.5.2.3 Constraints on the brightness constant

13.5.3 Brightness constant equation

13.5.4 Constraints on the brightness constant



13.6. Video segmentation

13.6.1. Introduction to segmentation: pixel input, pixel output

13.6.2 Convnets are classified

13.6.3 R-CNN

13.6.4 U-Net Architecture

13.6.4.1 Shrink phase

13.6.4.2 Expansion Phase

13.6.4.3 U-Net Summary

13.6.5 Image segmentation and video segmentation





14 3D

14.1 3D Method

14.1.1. Flight time

14.1.2. Lidar

14.1.3. Structured light

14.1.4. Motion construction

14.1.4.1 Introduction: Reconstruct scene geometry and camera position from two or more images

14.1.4.2 Pixel mapping: Tracking

Harris Corner

SIFT

Scale space

Descriptor

Object Detection

SuperPoint

Image robust matching strategy

(a) Key point space outlier rejection

(b) Match many features - find a good identical graph

RANSAC cycle

SuperGlue

LoFTR: Transformer-based local feature matching without detector

Key point tracking: Lucas-Kanade Tracker

affine cameras



14.1.4.3 Projection model

Affine structure in motion affine structure

Affine ambiguity. Affine ambiguity





14.1.5. Stereoscopic imaging

14.1.5.1.3D Video Principles

14.1.5.2. Stereo depth

14.1.5.3. Stereo matching



14.2 3D meets deep learning

14.2.1 Introduction to 3D

14.2.2 3D CNN volume data



14.3 GAN for 3D

14.3.1 From single image to volume

14.3.2 From single image to point cloud

14.3.3 From image to shape

14.3.4 From image to surface
